{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16330fba-d362-41f2-bc7c-22424f6a0636",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "# Configure logging.\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s %(levelname)s: %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    ")\n",
    "\n",
    "def pre_concatenate(embedding_dirs, csv_root, output_dir):\n",
    "    \"\"\"\n",
    "    For each CSV file in the directory structure of csv_root (which contains\n",
    "    subdirectories like fold-0, fold-1, fold-2 with train.csv, test.csv, and tune.csv),\n",
    "    this function loads all matching .pt files from embedding_dirs for each case_id.\n",
    "    The case_id (from the CSV) is only a part of the slide's filename, so a partial\n",
    "    (substring) match is used to locate the corresponding .pt files. The matching tensors\n",
    "    are concatenated and saved in the corresponding output folder structure:\n",
    "    \n",
    "      output_dir/fold-*/[train|tune|test]/{case_id}.pt\n",
    "    \"\"\"\n",
    "    logging.info(\"Starting pre-concatenation process\")\n",
    "    \n",
    "    # Ensure the output root exists.\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        logging.info(\"Created output directory: %s\", output_dir)\n",
    "    \n",
    "    # List fold directories (expecting names like fold-0, fold-1, fold-2)\n",
    "    fold_dirs = [d for d in os.listdir(csv_root) if os.path.isdir(os.path.join(csv_root, d)) and d.startswith(\"fold-\")]\n",
    "    if not fold_dirs:\n",
    "        logging.error(\"No fold directories found in csv_root: %s\", csv_root)\n",
    "        return\n",
    "\n",
    "    for fold in sorted(fold_dirs):\n",
    "        fold_path = os.path.join(csv_root, fold)\n",
    "        # Process each CSV file in the fold (train.csv, test.csv, tune.csv)\n",
    "        for split in [\"train\", \"tune\", \"test\"]:\n",
    "            csv_filename = f\"{split}.csv\"\n",
    "            csv_path = os.path.join(fold_path, csv_filename)\n",
    "            if not os.path.isfile(csv_path):\n",
    "                logging.warning(\"CSV file '%s' not found in fold '%s'. Skipping.\", csv_filename, fold)\n",
    "                continue\n",
    "\n",
    "            logging.info(\"Processing CSV file: %s\", csv_path)\n",
    "            df = pd.read_csv(csv_path)\n",
    "            logging.info(\"CSV loaded. Total rows: %d\", len(df))\n",
    "            \n",
    "            # Check that the CSV contains a \"case_id\" column.\n",
    "            if \"case_id\" not in df.columns:\n",
    "                logging.error(\"CSV file '%s' does not contain a 'case_id' column. Skipping.\", csv_path)\n",
    "                continue\n",
    "\n",
    "            # Create output subdirectory for this fold and split.\n",
    "            for idx, row in df.iterrows():\n",
    "                # Directly use the \"case_id\" value, knowing the column exists.\n",
    "                case_id = str(row[\"case_id\"])\n",
    "                matching_paths = []\n",
    "\n",
    "                for directory_path in embedding_dirs:\n",
    "                    if not os.path.isdir(directory_path):\n",
    "                        logging.warning(\"'%s' is not a valid directory. Skipping.\", directory_path)\n",
    "                        continue\n",
    "\n",
    "                    # PARTIAL MATCH: Check if the case_id substring is found anywhere in the filename.\n",
    "                    files = [f for f in os.listdir(directory_path) if f.endswith('.pt')]\n",
    "                    matched = [\n",
    "                        os.path.join(directory_path, f)\n",
    "                        for f in files\n",
    "                        if case_id in f  # substring matching since case_id is part of the slide name\n",
    "                    ]\n",
    "                    if matched:\n",
    "                        logging.debug(\"Found %d matching files for case_id '%s' in '%s'.\", \n",
    "                                      len(matched), case_id, directory_path)\n",
    "                    matching_paths.extend(matched)\n",
    "\n",
    "                if len(matching_paths) == 0:\n",
    "                    logging.warning(\"No .pt file found for '%s'. Skipping row %d.\", case_id, idx)\n",
    "                    continue\n",
    "\n",
    "                # Load and concatenate all matching tensors.\n",
    "                bags = []\n",
    "                for path in matching_paths:\n",
    "                    logging.debug(\"Loading tensor from: %s\", path)\n",
    "                    bag = torch.load(path)\n",
    "                    # If bag is [1024, N] and needs transposition to [N, 1024]\n",
    "                    if bag.ndim == 2 and bag.shape[0] == 1024 and bag.shape[1] != 1024:\n",
    "                        logging.debug(\"Transposing tensor for case_id '%s' from shape %s\", case_id, bag.shape)\n",
    "                        bag = bag.transpose(0, 1)\n",
    "                    bags.append(bag)\n",
    "\n",
    "                concatenated_bag = torch.cat(bags, dim=0)\n",
    "                output_path = os.path.join(\"/data/temporary/amirhosein/model_script_concatenated\", f\"{case_id}.pt\")\n",
    "                torch.save(concatenated_bag, output_path)\n",
    "                logging.info(\"Saved concatenated tensor for case_id '%s' to '%s'\", case_id, output_path)\n",
    "\n",
    "    logging.info(\"Pre-concatenation process completed successfully.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace these paths with your actual directories.\n",
    "    breast_dir = \"/data/temporary/amirhosein/modelscript_breast/pt_files\"\n",
    "    bladder_dir = \"/data/temporary/amirhosein/model_script_bladder/pt_files\"\n",
    "    prostate_dir = \"/data/temporary/amirhosein/model_script_prostate/pt_files\"\n",
    "    \n",
    "    embedding_dirs = [breast_dir, bladder_dir, prostate_dir]\n",
    "    csv_root = \"/data/temporary/projects/mutation-prediction/csvs/3-folds-prostate-bladder-breast\"  # This directory should contain fold-0, fold-1, fold-2 subdirectories.\n",
    "    output_dir = \"/data/temporary/amirhosein/model_script_concatenated\"\n",
    "    \n",
    "    pre_concatenate(embedding_dirs, csv_root, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89696eab-10af-49bc-8eb9-d970591e5a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-27 09:04:57 INFO: Script started\n",
      "2025-02-27 09:04:57 INFO: Using device: cpu\n",
      "2025-02-27 09:04:57 INFO: === Starting FOLD 0 ===\n",
      "2025-02-27 09:04:57 INFO: Loading datasets for fold 0\n",
      "2025-02-27 09:04:57 INFO: Reading CSV file: /data/temporary/projects/mutation-prediction/csvs/3-folds-prostate-only/fold-0/train.csv\n",
      "2025-02-27 09:04:57 INFO: CSV loaded. Total rows: 211\n",
      "2025-02-27 09:04:58 WARNING: Concatenated file for case_id 'TCGA-XK-AAJR' not found at '/data/temporary/amirhosein/model_script_concatenated/TCGA-XK-AAJR.pt'.\n",
      "2025-02-27 09:04:59 WARNING: Concatenated file for case_id 'TCGA-G9-6367' not found at '/data/temporary/amirhosein/model_script_concatenated/TCGA-G9-6367.pt'.\n",
      "2025-02-27 09:05:00 WARNING: Concatenated file for case_id 'TCGA-XK-AAIR' not found at '/data/temporary/amirhosein/model_script_concatenated/TCGA-XK-AAIR.pt'.\n",
      "2025-02-27 09:05:00 INFO: Dataset initialized with 208 valid samples.\n",
      "2025-02-27 09:05:00 INFO: Reading CSV file: /data/temporary/projects/mutation-prediction/csvs/3-folds-prostate-only/fold-0/tune.csv\n",
      "2025-02-27 09:05:00 INFO: CSV loaded. Total rows: 53\n",
      "2025-02-27 09:05:01 INFO: Dataset initialized with 53 valid samples.\n",
      "2025-02-27 09:05:01 INFO: Reading CSV file: /data/temporary/projects/mutation-prediction/csvs/3-folds-prostate-only/fold-0/test.csv\n",
      "2025-02-27 09:05:01 INFO: CSV loaded. Total rows: 133\n",
      "2025-02-27 09:05:02 WARNING: Concatenated file for case_id 'TCGA-XK-AAJP' not found at '/data/temporary/amirhosein/model_script_concatenated/TCGA-XK-AAJP.pt'.\n",
      "2025-02-27 09:05:02 WARNING: Concatenated file for case_id 'TCGA-XK-AAJT' not found at '/data/temporary/amirhosein/model_script_concatenated/TCGA-XK-AAJT.pt'.\n",
      "2025-02-27 09:05:02 INFO: Dataset initialized with 131 valid samples.\n",
      "2025-02-27 09:05:02 INFO: Initializing model for fold 0\n",
      "2025-02-27 09:05:02 INFO: Initializing Attention model with input_dim=1024, M=500, L=128, branches=1\n",
      "2025-02-27 09:05:02 INFO: [Fold 0 | Epoch 1] Starting training\n",
      "2025-02-27 09:05:02 INFO: Starting training epoch\n",
      "2025-02-27 09:09:45 INFO: Finished training epoch: Avg Loss: 0.4344, Avg Error: 0.1202\n",
      "2025-02-27 09:09:45 INFO: [Fold 0 | Epoch 1] Training complete. Loss: 0.4344, Error: 0.1202\n",
      "2025-02-27 09:09:45 INFO: [Fold 0 | Epoch 1] Starting validation\n",
      "2025-02-27 09:09:45 INFO: Starting evaluation\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 211\u001b[0m\n\u001b[1;32m    208\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScript finished successfully\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 211\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 155\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    152\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Fold \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m | Epoch \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m] Training complete. Loss: \u001b[39m\u001b[38;5;132;01m%.4f\u001b[39;00m\u001b[38;5;124m, Error: \u001b[39m\u001b[38;5;132;01m%.4f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, fold_idx, epoch_idx, train_loss, train_error)\n\u001b[1;32m    154\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Fold \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m | Epoch \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m] Starting validation\u001b[39m\u001b[38;5;124m\"\u001b[39m, fold_idx, epoch_idx)\n\u001b[0;32m--> 155\u001b[0m val_loss, val_error, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Fold \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m | Epoch \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m] Validation complete. Loss: \u001b[39m\u001b[38;5;132;01m%.4f\u001b[39;00m\u001b[38;5;124m, Error: \u001b[39m\u001b[38;5;132;01m%.4f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, fold_idx, epoch_idx, val_loss, val_error)\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# Check if current epoch improved validation loss\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 64\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(model, loader, device)\u001b[0m\n\u001b[1;32m     61\u001b[0m all_probs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 64\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (bag, label) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loader):\n\u001b[1;32m     65\u001b[0m         logging\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating batch \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m - bag shape: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, batch_idx, bag\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     66\u001b[0m         bag \u001b[38;5;241m=\u001b[39m bag\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    651\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 652\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    655\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    656\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:692\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    691\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 692\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    694\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/data/temporary/amirhosein/AbMIL/AttentionDeepMIL/dataloader.py:78\u001b[0m, in \u001b[0;36mPreConcatenatedDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     76\u001b[0m label_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([tp53_val], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     77\u001b[0m logging\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading pre-concatenated tensor for case_id \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m from \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m, case_id, file_path)\n\u001b[0;32m---> 78\u001b[0m bag \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     81\u001b[0m     logging\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mApplying transform to bag for case_id \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m, case_id)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/serialization.py:699\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    697\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 699\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    701\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    702\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    703\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    704\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/serialization.py:230\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 230\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    232\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/serialization.py:211\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "from __future__ import print_function\n",
    "import logging\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data_utils\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "import torch.utils.data as data\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import random_split, ConcatDataset, DataLoader\n",
    "\n",
    "# Import your dataset and models\n",
    "from dataloader import PreConcatenatedDataset\n",
    "from model import Attention, GatedAttention\n",
    "\n",
    "# Configure logging to display timestamps and log levels.\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s %(levelname)s: %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    ")\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, device):\n",
    "    logging.info(\"Starting training epoch\")\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    epoch_error = 0.0\n",
    "\n",
    "    for batch_idx, (bag, label) in enumerate(loader):\n",
    "        logging.debug(\"Training batch %d - bag shape: %s\", batch_idx, bag.shape)\n",
    "        bag = bag.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss, _ = model.calculate_objective(bag, label)\n",
    "        error, _ = model.calculate_classification_error(bag, label)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_error += error\n",
    "\n",
    "    n = len(loader)\n",
    "    avg_loss = epoch_loss / n if n > 0 else 0.0\n",
    "    avg_error = epoch_error / n if n > 0 else 0.0\n",
    "    logging.info(\"Finished training epoch: Avg Loss: %.4f, Avg Error: %.4f\", avg_loss, avg_error)\n",
    "    return avg_loss, avg_error\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    logging.info(\"Starting evaluation\")\n",
    "    model.eval()\n",
    "    epoch_loss = 0.0\n",
    "    epoch_error = 0.0\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (bag, label) in enumerate(loader):\n",
    "            logging.debug(\"Evaluating batch %d - bag shape: %s\", batch_idx, bag.shape)\n",
    "            bag = bag.to(device)\n",
    "            label = label.to(device)\n",
    "            loss, _ = model.calculate_objective(bag, label)\n",
    "            error, _ = model.calculate_classification_error(bag, label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_error += error\n",
    "\n",
    "            # Predict probabilities\n",
    "            Y_prob, _, _ = model(bag)\n",
    "            prob = Y_prob.mean().item()  # average if multiple branches\n",
    "\n",
    "            all_labels.append(label.item())\n",
    "            all_probs.append(prob)\n",
    "\n",
    "    n = len(loader)\n",
    "    avg_loss = epoch_loss / n if n else 0.0\n",
    "    avg_error = epoch_error / n if n else 0.0\n",
    "    logging.info(\"Finished evaluation: Avg Loss: %.4f, Avg Error: %.4f\", avg_loss, avg_error)\n",
    "    return avg_loss, avg_error, all_labels, all_probs\n",
    "\n",
    "def main():\n",
    "    logging.info(\"Script started\")\n",
    "    \n",
    "    # Hardcoded configuration\n",
    "    use_cuda = False\n",
    "    device = torch.device(\"cuda\" if use_cuda and torch.cuda.is_available() else \"cpu\")\n",
    "    logging.info(\"Using device: %s\", device)\n",
    "\n",
    "    data_root = \"/data/temporary/projects/mutation-prediction/csvs/3-folds-prostate-only\"\n",
    "    #breast_dir = \"/data/temporary/amirhosein/modelscript_breast/pt_files\"\n",
    "    #bladder_dir = \"/data/temporary/amirhosein/model_script_bladder/pt_files\"\n",
    "    prostate_dir = \"/data/temporary/amirhosein/model_script_concatenated\"\n",
    "\n",
    "    model_type = \"attention\"  # or \"gated_attention\"\n",
    "    input_dim = 1024\n",
    "    hidden_dim = 500\n",
    "    attn_dim = 128\n",
    "    attn_branches = 1\n",
    "    epochs = 10\n",
    "    lr = 0.0005\n",
    "    weight_decay = 1e-5\n",
    "    patience = 7  # early stopping patience\n",
    "\n",
    "    embedding_dirs = prostate_dir\n",
    "\n",
    "    fold_metrics = {'precision': [], 'recall': [], 'auc': []}\n",
    "\n",
    "    # 3-fold cross-validation loop\n",
    "    for fold_idx in range(0, 3):\n",
    "        logging.info(\"=== Starting FOLD %d ===\", fold_idx)\n",
    "        fold_subdir = f\"fold-{fold_idx}\"\n",
    "        fold_path = os.path.join(data_root, fold_subdir)\n",
    "\n",
    "        train_csv = os.path.join(fold_path, \"train.csv\")\n",
    "        val_csv   = os.path.join(fold_path, \"tune.csv\")\n",
    "        test_csv  = os.path.join(fold_path, \"test.csv\")\n",
    "\n",
    "        logging.info(\"Loading datasets for fold %d\", fold_idx)\n",
    "        # Create datasets\n",
    "        train_dataset = PreConcatenatedDataset(embedding_dirs, train_csv)\n",
    "        val_dataset   = PreConcatenatedDataset(embedding_dirs, val_csv)\n",
    "        test_dataset  = PreConcatenatedDataset(embedding_dirs, test_csv)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, pin_memory=True)\n",
    "        val_loader   = DataLoader(val_dataset, batch_size=1, shuffle=False, pin_memory=True)\n",
    "        test_loader  = DataLoader(test_dataset, batch_size=1, shuffle=False, pin_memory=True)\n",
    "\n",
    "        # Initialize model\n",
    "        logging.info(\"Initializing model for fold %d\", fold_idx)\n",
    "        if model_type == \"attention\":\n",
    "            model = Attention(input_dim=input_dim, M=hidden_dim, L=attn_dim, attention_branches=attn_branches)\n",
    "        else:\n",
    "            model = GatedAttention(input_dim=input_dim, M=hidden_dim, L=attn_dim, attention_branches=attn_branches)\n",
    "        model.to(device)\n",
    "\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "        # Training and validation loop with early stopping\n",
    "        best_val_loss = float(\"inf\")\n",
    "        best_state_dict = None\n",
    "        no_improvement_counter = 0\n",
    "\n",
    "        for epoch_idx in range(1, epochs + 1):\n",
    "            logging.info(\"[Fold %d | Epoch %d] Starting training\", fold_idx, epoch_idx)\n",
    "            train_loss, train_error = train_one_epoch(model, train_loader, optimizer, device)\n",
    "            logging.info(\"[Fold %d | Epoch %d] Training complete. Loss: %.4f, Error: %.4f\", fold_idx, epoch_idx, train_loss, train_error)\n",
    "            \n",
    "            logging.info(\"[Fold %d | Epoch %d] Starting validation\", fold_idx, epoch_idx)\n",
    "            val_loss, val_error, _, _ = evaluate(model, val_loader, device)\n",
    "            logging.info(\"[Fold %d | Epoch %d] Validation complete. Loss: %.4f, Error: %.4f\", fold_idx, epoch_idx, val_loss, val_error)\n",
    "\n",
    "            # Check if current epoch improved validation loss\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_state_dict = model.state_dict()\n",
    "                no_improvement_counter = 0\n",
    "                logging.info(\"[Fold %d | Epoch %d] New best model found (Validation Loss: %.4f)\", fold_idx, epoch_idx, best_val_loss)\n",
    "            else:\n",
    "                no_improvement_counter += 1\n",
    "                logging.info(\"[Fold %d | Epoch %d] No improvement. Counter: %d\", fold_idx, epoch_idx, no_improvement_counter)\n",
    "\n",
    "            # If no improvement for \"patience\" epochs, break early\n",
    "            if no_improvement_counter >= patience:\n",
    "                logging.info(\"[Fold %d] Early stopping triggered after %d epochs with no improvement.\", fold_idx, patience)\n",
    "                break\n",
    "\n",
    "        # Load best model for testing\n",
    "        if best_state_dict:\n",
    "            model.load_state_dict(best_state_dict)\n",
    "            logging.info(\"Best model loaded for fold %d\", fold_idx)\n",
    "\n",
    "        # Testing\n",
    "        logging.info(\"Starting testing for fold %d\", fold_idx)\n",
    "        test_loss, test_error, y_true, y_scores = evaluate(model, test_loader, device)\n",
    "        logging.info(\"[Fold %d] Testing complete. Loss: %.4f, Error: %.4f\", fold_idx, test_loss, test_error)\n",
    "\n",
    "        # Compute metrics\n",
    "        y_pred = [1 if p >= 0.5 else 0 for p in y_scores]\n",
    "        precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "        recall    = recall_score(y_true, y_pred, zero_division=0)\n",
    "        try:\n",
    "            auc_val = roc_auc_score(y_true, y_scores)\n",
    "        except ValueError:\n",
    "            auc_val = float('nan')\n",
    "\n",
    "        logging.info(\"[Fold %d] Metrics - Precision: %.4f, Recall: %.4f, AUC: %.4f\", fold_idx, precision, recall, auc_val)\n",
    "\n",
    "        fold_metrics['precision'].append(precision)\n",
    "        fold_metrics['recall'].append(recall)\n",
    "        fold_metrics['auc'].append(auc_val)\n",
    "\n",
    "    # After 3 folds, compute and log average metrics\n",
    "    avg_precision = sum(fold_metrics['precision']) / 3\n",
    "    avg_recall    = sum(fold_metrics['recall'])    / 3\n",
    "    valid_aucs    = [a for a in fold_metrics['auc'] if not (isinstance(a, float) and (a != a))]\n",
    "    avg_auc       = sum(valid_aucs) / len(valid_aucs) if valid_aucs else float('nan')\n",
    "\n",
    "    logging.info(\"=== 3-FOLD CROSS-VALIDATION RESULTS ===\")\n",
    "    logging.info(\"Average Precision: %.4f\", avg_precision)\n",
    "    logging.info(\"Average Recall:    %.4f\", avg_recall)\n",
    "    logging.info(\"Average AUC:       %.4f\", avg_auc)\n",
    "    logging.info(\"Script finished successfully\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ae4edc-7440-4580-8a87-54d81a91f340",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
